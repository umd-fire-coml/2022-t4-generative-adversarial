{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM1MH+xHr8Dhuba613f957C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Model Trainer\n","Use this notebook to train the model on a dataset of audio. You'll likely want to have a dataset of **one genre** of audio/music for best results and compatibility with frontend. \n","\n","This notebook mounts your Google Drive so you can point it to your dataset.\n","\n","## Important Note\n","If the specified genre is \"example\", the dataset directory path input will be ignored and the notebook will instead download an example dataset for training.\n","This is for demonstration purposes."],"metadata":{"id":"2ZJupI5dJFwE"}},{"cell_type":"code","source":["#@title Setup\n","\n","%cd /content\n","!git clone https://github.com/marcoppasini/musika\n","%cd musika\n","!pip install -r requirements.txt\n","!pip install --upgrade --no-cache-dir gdown\n","!apt install unzip\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"id":"nfnlPfOcKZqK","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Inputs { run: \"auto\" }\n","#@markdown Name of audio genre\n","genre_name = \"example\" #@param {type: \"string\"}\n","#@markdown Path to folder containing audio dataset\n","dataset_path = \"/path/to/audio/dir\" #@param {type: \"string\"}\n"],"metadata":{"id":"ThPhYaMnI6Pg","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Encode dataset\n","import gdown, os, subprocess\n","if genre_name == \"example\":\n","  dataset_path = \"/content/dataset\"\n","  if not os.path.exists(dataset_path + \".zip\"):\n","    dataset_url = \"https://drive.google.com/uc?id=15iroZ6Sh89pFuL41gd-Q1rkdhmb7DKzJ\"\n","    gdown.download(dataset_url, dataset_path + \".zip\")\n","  if not os.path.exists(dataset_path):\n","    subprocess.check_output([\"unzip\", dataset_path + \".zip\", \"-d\", \"/content\"])\n","\n","!python musika_encode.py --files_path $dataset_path --save_path /content/{genre_name}_encodings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XuXkzVX7KSG7","executionInfo":{"status":"ok","timestamp":1670481163234,"user_tz":300,"elapsed":544957,"user":{"displayName":"Avik Rao","userId":"14009663074948552767"}},"outputId":"a7eb82ec-422f-4cff-820d-5393437d42e5","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=15iroZ6Sh89pFuL41gd-Q1rkdhmb7DKzJ\n","To: /content/dataset.zip\n","100%|██████████| 5.40G/5.40G [02:09<00:00, 41.7MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Using GPU with mixed precision enabled...\n","\n","Checking if models are already available...\n","Downloading: 100% 19.2M/19.2M [00:00<00:00, 59.4MB/s]\n","Downloading: 100% 16.0M/16.0M [00:00<00:00, 43.4MB/s]\n","Downloading: 100% 50.8M/50.8M [00:00<00:00, 59.4MB/s]\n","Downloading: 100% 26.6M/26.6M [00:00<00:00, 59.1MB/s]\n","Downloading: 100% 83.2M/83.2M [00:01<00:00, 58.7MB/s]\n","Downloading: 100% 62.2M/62.2M [00:04<00:00, 14.5MB/s]\n","Downloading: 100% 62.2M/62.2M [00:00<00:00, 100MB/s]\n","Downloading: 100% 124M/124M [00:01<00:00, 95.2MB/s]\n","Downloading: 100% 166M/166M [00:01<00:00, 98.2MB/s]\n","Downloading: 100% 132/132 [00:00<00:00, 129kB/s]\n","Downloading: 100% 83.2M/83.2M [00:00<00:00, 96.1MB/s]\n","Downloading: 100% 62.2M/62.2M [00:00<00:00, 93.1MB/s]\n","Downloading: 100% 62.2M/62.2M [00:00<00:00, 93.1MB/s]\n","Downloading: 100% 124M/124M [00:01<00:00, 95.4MB/s]\n","Downloading: 100% 166M/166M [00:02<00:00, 82.1MB/s]\n","Downloading: 100% 132/132 [00:00<00:00, 195kB/s]\n","Downloading: 100% 67.2M/67.2M [00:00<00:00, 100MB/s] \n","Downloading: 100% 48.2M/48.2M [00:00<00:00, 98.0MB/s]\n","Downloading: 100% 48.2M/48.2M [00:00<00:00, 70.7MB/s]\n","Downloading: 100% 96.1M/96.1M [00:01<00:00, 92.0MB/s]\n","Downloading: 100% 134M/134M [00:01<00:00, 79.6MB/s]\n","Downloading: 100% 132/132 [00:00<00:00, 143kB/s]\n","Models are available!\n","/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n","Encoders/Decoders loaded from checkpoints/ae\n","Networks initialized\n"," 18% 103/586 [04:39<21:50,  2.71s/it, Saved Files=543]\n","Traceback (most recent call last):\n","  File \"musika_encode.py\", line 24, in <module>\n","    U.compress_files(models_ls)\n","  File \"/content/musika/utils_encode.py\", line 97, in compress_files\n","  File \"/content/musika/utils.py\", line 188, in distribute_enc\n","    res = model(x[i * bs : i * bs + bs], training=False)\n","  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 557, in __call__\n","    return super().__call__(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1097, in __call__\n","    outputs = call_fn(inputs, *args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 510, in call\n","    return self._run_internal_graph(inputs, training=training, mask=mask)\n","  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 666, in _run_internal_graph\n","    args, kwargs = node.map_arguments(tensor_dict)\n","  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/node.py\", line 175, in map_arguments\n","    flat_arguments = copy.copy(self._flat_arguments)\n","  File \"/usr/lib/python3.8/copy.py\", line 76, in copy\n","    return copier(x)\n","KeyboardInterrupt\n","^C\n","Traceback (most recent call last):\n","  File \"musika_train.py\", line 5, in <module>\n","    from parse.parse_train import parse_args\n","  File \"/content/musika/parse/parse_train.py\", line 3, in <module>\n","\n","^C\n"]}]},{"cell_type":"code","source":["#@title Train model on dataset\n","!python musika_train.py --train_path /content/{genre_name}_encodings\n","\n","default_checkpoints = {\"ae\", \"misc\", \"misc_small\", \"techno\"}\n","weight_dir = [chk for chk in os.listdir(\"/content/musika/checkpoints\") if chk not in default_checkpoints][0]\n","print(f\"Folder with model checkpoints and respective weights: /content/musika/checkpoints/{weight_dir}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xng2lnOnciLB","executionInfo":{"status":"ok","timestamp":1670482293282,"user_tz":300,"elapsed":2,"user":{"displayName":"Avik Rao","userId":"14009663074948552767"}},"outputId":"f99a8831-ee36-4d8c-fe32-f8a2d8b24649"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Folder with model checkpoints and respective weights: /content/musika/checkpoints/MUSIKA_latlen_256_latdepth_64_sr_44100_time_20221208-063552\n"]}]}]}